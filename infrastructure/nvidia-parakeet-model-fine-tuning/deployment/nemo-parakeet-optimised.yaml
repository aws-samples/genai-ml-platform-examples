---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-parakeet
  labels:
    app: nemo-parakeet
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nemo-parakeet
  template:
    metadata:
      labels:
        app: nemo-parakeet
    spec:
      tolerations:
        - key: "model-inferencing"
          operator: "Equal"
          value: "gpu-general"
          effect: "NoSchedule"
      volumes:
      - name: lustre-models
        persistentVolumeClaim:
          claimName: lustre-models-pvc
      containers:
      - name: nemo-parakeet
        image: <fixme>.amazonaws.com/hh/nemo-parakeet:v7
        ports:
        - containerPort: 8080
        resources:
          limits:
            cpu: "8"
            memory: 32Gi
            nvidia.com/gpu: "1"
          requests:
            cpu: "8"
            memory: 32Gi
            nvidia.com/gpu: "1"
        volumeMounts:
        - mountPath: /models
          name: lustre-models

        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 20
          periodSeconds: 5
          failureThreshold: 20
          successThreshold: 1
          timeoutSeconds: 5

        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 20
          periodSeconds: 5
          failureThreshold: 20
          successThreshold: 1
          timeoutSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: nemo-parakeet
  namespace: lws-demo
  labels:
    app: nemo-parakeet
spec:
  ports:
  - name: http-nemo-parakeet
    port: 8080
    protocol: TCP
    targetPort: 8080
  # The label selector should match the deployment labels & it is useful for prefix caching feature
  selector:
    app: nemo-parakeet
  sessionAffinity: None
  type: ClusterIP          


---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: nemo-parakeet-metrics
  namespace: lws-demo
  labels:
    release: prometheus
spec:
  selector:
    matchLabels:
      app: nemo-parakeet
  endpoints:
    - port: http-nemo-parakeet
      path: /metrics
      interval: 15s
  namespaceSelector:
    matchNames:
      # This should be the namespace where your vLLM service is running.
      - lws-demo

---
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: nemo-parakeet-keda-scaler
  namespace: lws-demo # Make sure this is the same namespace as your nemo-parakeet deployment
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nemo-parakeet
  minReplicaCount: 1
  maxReplicaCount: 5 # Adjust the max number of replicas as needed
  pollingInterval: 5 # How often KEDA will check the metric (in seconds)
  cooldownPeriod: 120 # The period to wait after the last trigger before scaling down
  triggers:
    - type: prometheus
      metadata:
        # This should be the address of your Prometheus server.
        # This is a common address for Prometheus installed via the kube-prometheus-stack.
        serverAddress: http://prometheus-operated.monitoring.svc.cluster.local:9090
        query: |
            avg(max_over_time(nemo_asr_request_latency_seconds_avg[10m]))
        threshold: "1"
        ignoreNullValues: "true"