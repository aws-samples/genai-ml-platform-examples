{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_s3_csv(account_id, bucket_name, file_key, region_name='us-east-1'):\n",
    "    \"\"\"\n",
    "    Read a CSV file from S3 and return the first 5 lines\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    bucket_name : str\n",
    "        Name of the S3 bucket\n",
    "    file_key : str\n",
    "        Path to the CSV file in S3 (e.g., 'folder/file.csv')\n",
    "    region_name : str\n",
    "        AWS region name (default: 'us-east-1')\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        First 5 rows of the CSV file\n",
    "    \"\"\"\n",
    "    # Create S3 client\n",
    "    s3_client = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "    try:\n",
    "        # Get temporary credentials for accessing S3 data using user profile role \n",
    "        s3control_client = boto3.client('s3control')\n",
    "        response = s3control_client.get_data_access(\n",
    "            AccountId=account_id,\n",
    "            Target=f's3://{bucket_name}/{file_key}',\n",
    "            Permission='READ'\n",
    "        )\n",
    "        credentials = response['Credentials']\n",
    "        \n",
    "        # Create an S3 client with the temporary credentials\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=credentials['AccessKeyId'],\n",
    "            aws_secret_access_key=credentials['SecretAccessKey'],\n",
    "            aws_session_token=credentials['SessionToken']\n",
    "        )\n",
    "        \n",
    "        objects = s3_client.list_objects(Bucket=bucket_name, Prefix=file_key)\n",
    "        \n",
    "        # Read the first part file into a pandas DataFrame\n",
    "        #first_part_key = f\"{output_key_prefix}/part-00000\"\n",
    "        obj = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "        data = obj['Body'].read().decode('utf-8')\n",
    "        df = pd.read_csv(io.StringIO(data), header=None)\n",
    "        \n",
    "        # Print the top 5 rows\n",
    "        print(f\"Top 5 rows from s3://{bucket_name}/{file_key}\")\n",
    "        print(df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV from S3: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_STS_REGIONAL_ENDPOINTS'] = 'regional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User A accessing their authorized S3 dataset \n",
    "\n",
    "#Get region\n",
    "boto3_session = boto3.Session()\n",
    "region = boto3_session.region_name\n",
    "\n",
    "# Get AWS account ID dynamically\n",
    "sts_client = boto3.client('sts', region_name=region)\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "\n",
    "# Replace  with your GrantsBucketName from cloudformation output\n",
    "bucket_name = \"<your-GrantsBucketName-from-cloudformation-output>\"\n",
    "file_key = \"UserA/abalone.csv\"  # or \"UserA/abalone.csv\" or \"UserB/abalone.csv\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "read_s3_csv(account_id, bucket_name, file_key, region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "<div style=\"padding: 15px; background-color: #d1ecf1; border-left: 5px solid #0c5460; color: #0c5460;\">\n",
    "<strong>ℹ️ Note:</strong> The following cell will throw an error, This is expected as UserA doesn't have permissions to access the dataset of UserB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User A accessing their unauthorized S3 dataset \n",
    "\n",
    "file_key = \"UserB/abalone.csv\"  # or \"UserA/abalone.csv\" or \"UserB/abalone.csv\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "read_s3_csv(account_id, bucket_name, file_key, region)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
