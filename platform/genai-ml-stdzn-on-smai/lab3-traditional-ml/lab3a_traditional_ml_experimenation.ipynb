{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional ML with Amazon SageMaker AI \n",
    "\n",
    "## Workshop Overview\n",
    "\n",
    "Welcome to this hands-on workshop on building traditional machine learning models with Amazon SageMaker! In this workshop, you'll learn how to:\n",
    "\n",
    "- **Set up** your SageMaker environment with the latest Python SDK v3\n",
    "- **Configure** MLflow for experiment tracking and model management\n",
    "- **Prepare** and process data for machine learning\n",
    "- **Train** an XGBoost model using SageMaker's ModelTrainer\n",
    "- **Build** and package models with ModelBuilder\n",
    "- **Deploy** models to real-time endpoints\n",
    "- **Test** and validate your deployed model\n",
    "- **Clean up** resources to avoid unnecessary costs\n",
    "\n",
    "### Business Problem for the workshop\n",
    "\n",
    "You'll work with a **bank marketing dataset** to predict whether a customer will subscribe to a term deposit based on:\n",
    "- Demographics (age, job, marital status, education)\n",
    "- Financial information (credit default, housing loan, personal loan)\n",
    "- Campaign data (contact type, month, day of week, duration)\n",
    "- Economic indicators (employment rate, consumer price index, etc.)\n",
    "\n",
    "This is a **binary classification** problem commonly faced by financial institutions and we will use this as an example to run the Traditional ML with Amazon SageMaker AI  workshop.\n",
    "\n",
    "### Dataset Information\n",
    "\n",
    "- **Source**: UCI Machine Learning Repository - Bank Marketing Dataset. \n",
    "- **Size**: ~41,000 records with 20 features\n",
    "- **Target**: Binary (yes/no) - Will the customer subscribe?\n",
    "- **Citation**: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing.\n",
    "\n",
    "### AWS Services Used\n",
    "\n",
    "- **Amazon SageMaker AI Training**: Managed training infrastructure\n",
    "- **Amazon SageMaker Endpoints**: Real-time model hosting\n",
    "- **Amazon SageMaker AI MLflow**: Experiment tracking and model registry\n",
    "- **Amazon S3**: Data and model artifact storage\n",
    "- **AWS IAM**: Security and access management\n",
    "- **SageMaker Python SDK v3**\n",
    "\n",
    "### Estimated Time\n",
    "\n",
    "- **Total**: 45-60 minutes\n",
    "- **Training**: ~5 minutes\n",
    "- **Deployment**: ~5-7 minutes\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- AWS account with SageMaker Studio access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Prerequisites & Setup\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**SageMaker Python SDK v3**: The latest version of the SageMaker SDK provides:\n",
    "- Simplified APIs for training and deployment\n",
    "- Better integration with MLflow\n",
    "- Improved resource management\n",
    "- Type hints and better IDE support\n",
    "- See [documentation](https://sagemaker.readthedocs.io/en/stable/) for more\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Run the cells below to set up your environment. The first cell may take 1-2 minutes to install packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# This may take 1-2 minutes on first run\n",
    "# Ignore dependency conflicts warnings and errors.\n",
    "!pip install --upgrade pip -q\n",
    "!pip install -Uq \"sagemaker==3.3.1\" \"boto3==1.42.30\" \"sagemaker-core==2.3.1\" \\\n",
    "    \"sagemaker-mlops==1.3.1\" \"sagemaker-serve\" \"mlflow==3.4.0\" \\\n",
    "    \"sagemaker-mlflow==0.2.0\" \"pandas\" \"scikit-learn\" \"xgboost\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# SageMaker v3 imports\n",
    "from sagemaker.train.model_trainer import ModelTrainer\n",
    "from sagemaker.core.training.configs import SourceCode, InputData, Compute\n",
    "from sagemaker.core.helper.session_helper import Session, get_execution_role\n",
    "from sagemaker.core import image_uris\n",
    "from sagemaker.serve.model_builder import ModelBuilder\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder\n",
    "\n",
    "print('âœ“ All libraries imported successfully')\n",
    "print(f'MLflow version: {mlflow.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker session and get AWS configuration\n",
    "sagemaker_session = Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'bank-marketing-lab'\n",
    "\n",
    "print('AWS Configuration:')\n",
    "print(f'  Region: {region}')\n",
    "print(f'  S3 Bucket: {bucket}')\n",
    "print(f'  IAM Role: {role}')\n",
    "print(f'  Data Prefix: {prefix}')\n",
    "print('\\n SageMaker session initialized successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: SageMakerAI MLflow App Configuration\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "In this section, you'll:\n",
    "1. Connect to your SageMaker AI MLflow app\n",
    "2. Create or select an MLflow experiment\n",
    "3. Understand MLflow's role in experiment tracking\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Amazon SageMaker AI MLflow App**: A fully managed SageMakerAI service that provides:\n",
    "- **Experiment Tracking**: Log parameters, metrics, and artifacts\n",
    "- **Model Registry**: Version and manage models. \n",
    "- **SageMakerAI integration**: Automatically, register models to SageMakerAI Model Registry\n",
    "- **Reproducibility**: Track code versions and dependencies\n",
    "- **Collaboration**: Share experiments across teams\n",
    "- **Integration**: Works seamlessly with SageMaker training\n",
    "\n",
    "**MLflow Experiment**: A logical grouping of runs that:\n",
    "- Organizes related training attempts\n",
    "- Enables comparison of different approaches\n",
    "- Tracks the evolution of your model\n",
    "\n",
    "**MLflow Run**: A single execution that logs:\n",
    "- Hyperparameters (learning rate, tree depth, etc.)\n",
    "- Metrics (accuracy, precision, recall, AUC)\n",
    "- Artifacts (model files, plots, data samples)\n",
    "- Metadata (start time, duration, user)\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Find your MLflow App ARN**:\n",
    "   - In SageMaker Studio, navigate to the left sidebar\n",
    "   - Click on \"MLflow\" palen under \"Applications\"\n",
    "   - Find your MLflow app (usually named \"DefaultMLFlowApp\"). For the first time, it will take 1-2mins to launch\n",
    "   - Copy the ARN if you need to use a specific app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MLflow app connection\n",
    "# Update this if you want to use a specific MLflow app\n",
    "mlflow_app_name = 'DefaultMLFlowApp'\n",
    "\n",
    "# Get MLflow app ARN\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "mlflow_list = sm_client.list_mlflow_apps()\n",
    "\n",
    "print(f'Found {len(mlflow_list[\"Summaries\"])} MLflow app(s) in your account:')\n",
    "for app in mlflow_list['Summaries']:\n",
    "    print(f'  - {app[\"Name\"]}')\n",
    "\n",
    "# Find the specified MLflow app\n",
    "mlflow_app_arn = None\n",
    "for mlflow_app in mlflow_list['Summaries']:\n",
    "    if mlflow_app['Name'] == mlflow_app_name:\n",
    "        mlflow_app_arn = mlflow_app['Arn']\n",
    "        break\n",
    "\n",
    "if mlflow_app_arn:\n",
    "    print(f'\\n Using MLflow app: {mlflow_app_name}')\n",
    "    print(f'  ARN: {mlflow_app_arn}')\n",
    "else:\n",
    "    raise ValueError(f'MLflow app \"{mlflow_app_name}\" not found. Please check the name or create one in SageMaker Studio.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow tracking URI and create/select experiment\n",
    "mlflow.set_tracking_uri(mlflow_app_arn)\n",
    "mlflow_experiment_name = 'bank-marketing-prediction'\n",
    "\n",
    "try:\n",
    "    # Try to create a new experiment\n",
    "    experiment_id = mlflow.create_experiment(mlflow_experiment_name)\n",
    "    print(f' Created new MLflow experiment: {mlflow_experiment_name}')\n",
    "    print(f'  Experiment ID: {experiment_id}')\n",
    "except:\n",
    "    # Experiment already exists, set it as active\n",
    "    mlflow.set_experiment(mlflow_experiment_name)\n",
    "    experiment = mlflow.get_experiment_by_name(mlflow_experiment_name)\n",
    "    print(f' Using existing MLflow experiment: {mlflow_experiment_name}')\n",
    "    print(f'  Experiment ID: {experiment.experiment_id}')\n",
    "\n",
    "print('\\n You can view your experiments in the SageMaker Studio MLflow App UI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Data Preparation\n",
    "\n",
    "In this section, you'll:\n",
    "1. Download the bank marketing dataset\n",
    "2. Explore and understand the data\n",
    "3. Preprocess features (encoding categorical variables)\n",
    "4. Split data into training and test sets\n",
    "5. Upload data to Amazon S3\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Data Preprocessing**: Essential steps to prepare raw data for machine learning:\n",
    "- **Categorical Encoding**: Convert text categories (job, education) to numbers\n",
    "- **Train-Test Split**: Separate data to evaluate model performance\n",
    "- **Stratification**: Maintain class balance in splits (important for imbalanced data)\n",
    "\n",
    "### Dataset Features\n",
    "\n",
    "- **Client Demographics**: Includes age, job type, marital status, and education level\n",
    "- **Financial Profile**: Tracks credit default status, housing loans, and personal loans (yes/no indicators)\n",
    "- **Campaign Details**: Captures contact method, timing (month/day), call duration, number of contacts, and previous campaign outcomes\n",
    "- **Economic Indicators**: Incorporates macroeconomic context including employment variation rate, consumer price/confidence indices, Euribor rate, and employment numbers\n",
    "- **Target Variable**: Binary classification goal â€” predicting whether a client subscribed to a term deposit (yes/no)\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Run the cells below to download, explore, and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the dataset\n",
    "print('Downloading bank marketing dataset...')\n",
    "!wget -N https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
    "!unzip -o bank-additional.zip\n",
    "print('\\nâœ“ Dataset downloaded and extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
    "print(f'Shape: {df.shape}\\nTarget distribution:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "cat_cols = [c for c in df.select_dtypes(include=['object']).columns if c != 'y']\n",
    "for col in cat_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# Encode target\n",
    "df['y'] = (df['y'] == 'yes').astype(int)\n",
    "print(f'âœ“ Encoded {len(cat_cols)} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X, y = df.drop('y', axis=1), df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Save locally\n",
    "os.makedirs('data', exist_ok=True)\n",
    "pd.concat([y_train, X_train], axis=1).to_csv('data/train.csv', index=False, header=False)\n",
    "pd.concat([y_test, X_test], axis=1).to_csv('data/test.csv', index=False, header=False)\n",
    "print(f'Train: {X_train.shape}, Test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "train_s3 = sagemaker_session.upload_data('data/train.csv', bucket, f'{prefix}/data/train')\n",
    "test_s3 = sagemaker_session.upload_data('data/test.csv', bucket, f'{prefix}/data/test')\n",
    "print(f'Train S3: {train_s3}\\nTest S3: {test_s3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Model Training with ModelTrainer\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "In this section, you'll:\n",
    "1. Create a training script for XGBoost\n",
    "2. Configure the ModelTrainer with hyperparameters\n",
    "3. Launch a SageMaker training job\n",
    "4. Monitor training progress and view results\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**ModelTrainer (SageMaker SDK v3)**: Simplified training API that:\n",
    "- Manages training infrastructure automatically\n",
    "- Handles script packaging and dependencies\n",
    "- Integrates with MLflow for tracking\n",
    "- Provides intelligent defaults\n",
    "- Supports distributed training\n",
    "\n",
    "**SageMaker Training Jobs**: Managed training infrastructure that:\n",
    "- Provisions compute instances automatically\n",
    "- Downloads data from S3\n",
    "- Runs your training script\n",
    "- Uploads model artifacts to S3\n",
    "- Terminates instances when done thus cost-efficient\n",
    "\n",
    "\n",
    "### Steps and Instructions\n",
    "\n",
    "1. **Create training script**: We'll write a Python script that trains XGBoost\n",
    "2. **Configure ModelTrainer**: Set up compute resources and hyperparameters\n",
    "3. **Start training**: Launch the job (takes ~5 minutes)\n",
    "4. **Monitor progress**: Watch logs in SageMaker AI Studio training job in real-time\n",
    "5. **View results**: Check MLflow for metrics and artifacts\n",
    "\n",
    "Run the cells below to train your model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training script directory\n",
    "os.makedirs('scripts', exist_ok=True)\n",
    "\n",
    "training_script = '''import argparse\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--max_depth', type=int, default=5)\n",
    "    parser.add_argument('--eta', type=float, default=0.2)\n",
    "    parser.add_argument('--gamma', type=int, default=4)\n",
    "    parser.add_argument('--min_child_weight', type=int, default=6)\n",
    "    parser.add_argument('--subsample', type=float, default=0.8)\n",
    "    parser.add_argument('--num_round', type=int, default=100)\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args, _ = parse_args()\n",
    "    \n",
    "    # Load data\n",
    "    train_data = pd.read_csv('/opt/ml/input/data/train/train.csv', header=None)\n",
    "    test_data = pd.read_csv('/opt/ml/input/data/test/test.csv', header=None)\n",
    "    \n",
    "    X_train, y_train = train_data.iloc[:, 1:], train_data.iloc[:, 0]\n",
    "    X_test, y_test = test_data.iloc[:, 1:], test_data.iloc[:, 0]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    # Set MLFlow specifics\n",
    "    mlflow_app_arn = os.environ.get('MLFLOW_TRACKING_URI', None)\n",
    "    mlflow_experiment_name = os.environ.get('MLFLOW_EXP', None)\n",
    "    # MLflow setup\n",
    "    mlflow.set_tracking_uri(mlflow_app_arn)\n",
    "    mlflow.set_experiment(mlflow_experiment_name)\n",
    "    \n",
    "    # Enable autologging - captures everything automatically\n",
    "    # mlflow.xgboost.autolog()\n",
    "    mlflow.xgboost.autolog(\n",
    "        log_input_examples=True,\n",
    "        log_model_signatures=True,\n",
    "        log_models=True,\n",
    "        log_datasets=True,\n",
    "        model_format=\"json\",  # Recommended for portability\n",
    "        registered_model_name=\"bank-prediction-XGBoostModel\",\n",
    "        extra_tags={\"team\": \"data-science\"},\n",
    "    )\n",
    "    \n",
    "    # MLflow tracking\n",
    "    with mlflow.start_run():\n",
    "        params = {\n",
    "            'max_depth': args.max_depth,\n",
    "            'eta': args.eta,\n",
    "            'gamma': args.gamma,\n",
    "            'min_child_weight': args.min_child_weight,\n",
    "            'subsample': args.subsample,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc'\n",
    "        }\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train\n",
    "        model = xgb.train(params, dtrain, args.num_round, evals=[(dtest, 'test')])\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred_proba = model.predict(dtest)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        mlflow.log_metrics(metrics)\n",
    "        print(f'Metrics: {metrics}')\n",
    "        \n",
    "        # Save model\n",
    "        model_path = '/opt/ml/model'\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        model.save_model(f'{model_path}/xgboost-model')\n",
    "        mlflow.xgboost.log_model(\n",
    "            model, \n",
    "            name=\"bank-prediction-XGBoostModel\"\n",
    "            )\n",
    "'''\n",
    "\n",
    "with open('scripts/train.py', 'w') as f:\n",
    "    f.write(training_script)\n",
    "    \n",
    "print('âœ“ Training script created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get XGBoost container image\n",
    "xgboost_image = image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.7-1', #3.0-5\n",
    "    py_version=\"py311\",\n",
    "    image_scope='training',\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")\n",
    "print(f'XGBoost image: {xgboost_image}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ModelTrainer with v3 API\n",
    "source_code = SourceCode(\n",
    "    source_dir='scripts',\n",
    "    entry_script='train.py',\n",
    "    requirements=\"requirements.txt\"\n",
    ")\n",
    "\n",
    "compute = Compute(\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=1,\n",
    "    volume_size_in_gb=30\n",
    ")\n",
    "\n",
    "hyperparameters = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.2,\n",
    "    'gamma': 4,\n",
    "    'min_child_weight': 6,\n",
    "    'subsample': 0.8,\n",
    "    'num_round': 100\n",
    "}\n",
    "\n",
    "model_trainer = ModelTrainer(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    training_image=xgboost_image,\n",
    "    source_code=source_code,\n",
    "    compute=compute,\n",
    "    hyperparameters=hyperparameters,\n",
    "    base_job_name='bank-marketing-xgboost',\n",
    "    environment={'MLFLOW_TRACKING_URI': mlflow_app_arn,\n",
    "                 'MLFLOW_EXP': mlflow_experiment_name\n",
    "                }\n",
    ")\n",
    "\n",
    "print('ModelTrainer configured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "input_data_train = InputData(channel_name='train', data_source=train_s3)\n",
    "input_data_test = InputData(channel_name='test', data_source=test_s3)\n",
    "\n",
    "model_trainer.train(\n",
    "    input_data_config=[input_data_train, input_data_test],\n",
    "    wait=True\n",
    ")\n",
    "# Go the the sagemaker Studio training to find the training job in-progress with name \"bank-marketing-xgboost*\"\n",
    "print(f' Training completed: {model_trainer.latest_training_job.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Training Output\n",
    "\n",
    "Now let's explore what was automatically logged to MLflow during training!\n",
    "\n",
    "**Navigate to MLflow UI**\n",
    "1. In SageMaker Studio, click on **MLflow** in the left sidebar\n",
    "2. Find your MLflow app (DefaultMLFlowApp)\n",
    "3. Click to open the MLflow UI\n",
    "\n",
    "**View the Experiment**\n",
    "1. In MLflow UI, click on **Experiments** tab\n",
    "2. Find the experiment: **bank-marketing-prediction**\n",
    "3. You'll see your training run listed with:\n",
    "   - Run name and ID\n",
    "   - Start time and duration\n",
    "   - Status (Finished)\n",
    "   - Metrics preview\n",
    "\n",
    "**Explore the Run Details**\n",
    "\n",
    "Click on the run to see comprehensive details:\n",
    "\n",
    "- **Parameters Tab**: All hyperparameters used:\n",
    "- **Metrics Tab**: Training metrics over time.\n",
    "- **Artifacts Tab**: Model files (xgboost-model)\n",
    "- **View Registered Model**: The model was automatically registered in MLflow Model Registry!\n",
    "\n",
    "**Check SageMaker Model Registry Integration**\n",
    "\n",
    "MLflow automatically registered the model with SageMaker AI Model Registry:\n",
    "\n",
    "1. In SageMaker AI Studio, navigate to **Model** section in the left sidebar\n",
    "2. Look for model package group under `My models` : **bank-prediction-XGBoostModel**\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Compare Runs**: Train with different hyperparameters and compare in MLflow\n",
    "2. **Promote Model**: Approve model in registry for production use\n",
    "3. **Deploy Model**: Use the registered model for deployment\n",
    "\n",
    "Now let's prepare the model for deployment using ModelBuilder!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Build and Deploy Model with ModelBuilder\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "In this section, you'll:\n",
    "1. Retrieve trained model artifacts from S3\n",
    "2. Configure ModelBuilder for deployment\n",
    "3. Create input/output schemas for the model\n",
    "4. Build a deployable model package\n",
    "5. Deploy the model to a real-time SageMaker endpoint\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**ModelBuilder**: A SageMaker SDK v3 tool that:\n",
    "- Packages trained models for deployment\n",
    "- Handles container image selection\n",
    "- Creates model schemas automatically\n",
    "- Simplifies the deployment process\n",
    "- Supports multiple model formats (XGBoost, PyTorch, TensorFlow, etc.)\n",
    "\n",
    "**SageMaker Endpoints**: Real-time inference infrastructure that provides:\n",
    "- **Always-on HTTPS endpoint**: Available 24/7 for predictions\n",
    "- **Auto-scaling**: Handles variable traffic automatically\n",
    "- **Load balancing**: Distributes requests across instances\n",
    "- **Monitoring**: CloudWatch metrics for latency, errors, invocations\n",
    "- **Security**: VPC support, encryption, IAM authentication\n",
    "\n",
    "\n",
    "**Important**: Endpoints run continuously and incur charges:\n",
    "- Always delete endpoints when not in use\n",
    "- Use auto-scaling for variable workloads\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. **Get model artifacts**: Retrieve the S3 path from training job\n",
    "2. **Configure ModelBuilder**: Set up inference image and model data\n",
    "3. **Build model**: Package the model for deployment\n",
    "4. **Deploy endpoint**: Launch the endpoint (takes 5-7 minutes)\n",
    "5. **Verify deployment**: Check endpoint status\n",
    "\n",
    "Run the cells below to build and deploy your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model artifacts\n",
    "training_job_name = model_trainer._latest_training_job.training_job_name\n",
    "model_data_s3 = model_trainer._latest_training_job.model_artifacts.s3_model_artifacts\n",
    "print(f'Model artifacts: {model_data_s3}, training job: {training_job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get inference image URI\n",
    "inference_image = image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.7-1',\n",
    "    image_scope='inference'\n",
    ")\n",
    "print(f'Inference image: {inference_image}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ModelBuilder with trained model artifacts\n",
    "model_builder = ModelBuilder(\n",
    "    image_uri=inference_image,\n",
    "    s3_model_data_url=model_data_s3,\n",
    "    role_arn=role,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_name = f'bank-marketing-model-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "built_model = model_builder.build(model_name=model_name)\n",
    "\n",
    "print(f'Model built: {built_model.model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Deploy model to endpoint using ModelBuilder\n",
    "endpoint_name = f'bank-marketing-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "\n",
    "endpoint = model_builder.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "print(f' Endpoint deployed: {endpoint.endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Verify the endpoint creation. Go to the SageMaker AI Studio `Deployments -> Endpoints` and see the new Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Test SageMaker AI Endpoint by predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data in CSV format (XGBoost expects CSV without headers)\n",
    "test_sample = X_test.iloc[:5]\n",
    "test_csv = test_sample.to_csv(header=False, index=False)\n",
    "\n",
    "print('Test data (first 5 samples):')\n",
    "print(test_csv[:200] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using endpoint.invoke()\n",
    "response = endpoint.invoke(\n",
    "    body=test_csv,\n",
    "    content_type='text/csv'\n",
    ")\n",
    "\n",
    "# Parse predictions\n",
    "predictions_raw = response.body.read().decode('utf-8')\n",
    "predictions = [float(p) for p in predictions_raw.strip().split('\\n')]\n",
    "\n",
    "print('Sample Predictions:')\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f'  Sample {i+1}: {pred:.4f} (Class: {\"Yes\" if pred > 0.5 else \"No\"})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with actual labels\n",
    "actual_labels = y_test.iloc[:5].values\n",
    "print('\\nPrediction vs Actual:')\n",
    "for i, (pred, actual) in enumerate(zip(predictions, actual_labels)):\n",
    "    pred_class = 1 if pred > 0.5 else 0\n",
    "    match = 'âœ“' if pred_class == actual else 'âœ—'\n",
    "    print(f'  {match} Sample {i+1}: Predicted={pred_class}, Actual={actual}, Probability={pred:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Register Model to SageMaker AI Model Registry (Optional)\n",
    "\n",
    "> **Note**: The trained model is already registered in MLflow and if the auto-registration flag is enabled on the SageMakerAI MLflow App, SageMaker will automatically register the model from MLflow into SageMaker AI Model Registry. If you used the default MLflow app, then the auto-registration flag is enabled and subsequently the model from MLflow is registered automatically into SageMaker AI Model Registry. Alternatively, you can also register the model directly into SageMaker AI Model Registry as shown below.\n",
    "\n",
    "**SageMaker AI Model Registry**: A centralized model catalog that:\n",
    "- **Versions models**: Track model iterations over time\n",
    "- **Manages lifecycle**: Dev â†’ Staging â†’ Production stages\n",
    "- **Enables governance**: Approval workflows and audit trails\n",
    "- **Integrates with CI/CD**: Automated deployment pipelines\n",
    "- **Provides lineage**: Track training data, code, and metrics\n",
    "- **Supports multi-account**: Share models across AWS accounts\n",
    "- **Auto-Registration**: When enabled in MLflow app, Models logged to MLflow are automatically synced to SageMaker\n",
    "- **Model Package**: A SageMaker resource that contains: Model artifacts, Model metrics, Metadata.\n",
    "- **Model Package Group**: A collection of model versions helping Groups related model versions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_name = built_model.model_name+\"-manual\"\n",
    "step_response = model_builder.register(\n",
    "    model_package_group_name =  new_model_name,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.m5.xlarge\"],\n",
    "    approval_status=\"Approved\"\n",
    ")\n",
    "print(f\"New model registerd: {step_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Verify the manual model registration. Go to the SageMaker AI Studio `Models -> My Models` and see the new model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up section (Optional)\n",
    "Delete the endpoint as it is live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "response = endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop Summary: Traditional ML with Amazon SageMaker\n",
    "This workshop provided hands-on experience with the end-to-end machine learning workflow using Amazon SageMaker. Participants learned to:\n",
    "1. Train models using SageMaker's managed training infrastructure with ModelTrainer, leveraging on-demand compute (XGBoost on ml.m5.xlarge instances) without server management\n",
    "2. Track experiments with the fully managed Amazon SageMaker MLflow App, logging hyperparameters, metrics (accuracy, AUC, F1), and model artifacts\n",
    "3. Package models using ModelBuilder to prepare trained models for deployment with defined input/output schemas\n",
    "4. Deploy endpoints as fully managed, real-time HTTPS endpoints for low-latency predictions\n",
    "5. Manage model versions through automatic registration from MLflow to the SageMaker AI Model Registry\n",
    "6. The workshop utilized the SageMaker Python SDK v3, highlighting its simplified APIs, reduced boilerplate code, and intelligent defaults. \n",
    "\n",
    "You've successfully completed the Traditional ML with Amazon SageMaker workshop. You now have hands-on experience with:\n",
    "- SageMaker's core training and deployment capabilities\n",
    "- MLflow integration for experiment tracking\n",
    "- Real-world ML workflow from data to deployment\n",
    "- AWS best practices for ML operations\n",
    "\n",
    "### Next Steps with SageMaker\n",
    "\n",
    "**Explore More SageMaker Features:**\n",
    "- Create SageMaker Pipelines for automated retraining\n",
    "- Automate ML workflows with CI/CD\n",
    "- Implement model approval workflows\n",
    "\n",
    " Thank You! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
